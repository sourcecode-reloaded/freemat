
What is a dynamic variable?  Consider the following function

function foo
   A = fft(1:10);

In this case, we might think that "fft" is an external (global) symbol.  But 
not necessarily.  Consider the case of an eval statement:

function foo
   eval('fft = 1:10');
   A = fft(1:10);

The presence of an eval means that "fft" is now a variable.  So when we lookup
fft, we get a variable instead of the function.  The "eval" could just as
easily be hidden in a script

function foo
   do_script
   A = fft(1:10);

do_script
  fft = 1:10

So dynamic variables are ones that just ones that have to be defined at runtime.

Note that there is a problem in the current definition of local variables.  Consider

function foo
   a = 3;
   a = a + 5;

In this case, because "a" is not visible outside the scope of function "foo", it 
would be marked a local variable (it is defined before being used).  But what happens
if the variable is deleted?  Something like this:

function foo
   fft = 3;
   clear('fft');
   a = fft(1:15);

The "clear" function will delete the local variable "fft", and the next call to "fft"
will be mapped to the function "fft", not the local variable.  Yuck.  The presence of
"clear" means that "local" variables are an optimization that we cannot really make.
Instead, all variables that are not declared as global, persistent or defined as 
parameters are dynamic.

Instead of trying to do a bunch of complex analysis at compile time, I should have developed
a better cache mechanism so that variables could be looked up without a big penalty.  
Double yuck.

OK - so variables only come in the following flavors:

Global     - variables that belong to the global scope.
Persistent - variables that are "static".
Parameter  - variables that are passed as parameters (could be value or reference).
Return     - variables that are returned from a function.
Dynamic    - variables that are otherwise undefined.

The notion of "local" variables is dropped.  There is no real meaningful way to 
guarantee that a variable is truly local, except in the case of for loop variables.
And even in that case, it's really a function of speed - nothing else.  

What about "captured/free" variables?  This was considerably more difficult than regular
variables.  The situation was driven by the need/ability to nest functions.

function a = foo(y)
  x = 3+y
  function b = bar(g)
     b = x+g
  end
end

In this case, when the function "bar" is executed, it needs access to the variable "x", which
is in the parent function scope.  A fully dynamic version of this would be to create a code
object for "bar" that included a static scope with it.  The static scope would contain the 
variable "x".  When the function "bar" is executed outside the scope of "foo", it would
search through the static scope to find variables that are not defined in it.  So when we
return a function pointer

function a = foo(y)
  x = 3+y
  function b = bar(g)
     b = x+g
  end
  a = @bar
end

then "a" contains the code for "bar" and a workspace that defines "x".  So far, that's fine.
The question is what happens when we have to start chaining through scopes?  For example,

function a = foo(y)
  x = y + 2;
  function b = bar(g)
    k = x + g;
    function c = baz(p)
      c = p + k + x;
    end
    b = @baz
  end
  a = @b
end

So in this case, "baz" needs to access a variable "x" in the scope of "foo".  It seems that 
when we create the function pointer 

b = @baz

we need to create a workspace to store with it.  At that point, we walk through the function
scopes until we get to the parent scope and collect all variables that are defined.  So in this
case the function pointer b will have

b.code = <code>
b.workspace.x = <value for x>
b.workspace.k = <value for k>

When the code for "b" is executed, a "LOAD_DYN" reference for "x" will need to search the workspace
first.  

From a cache-implementation standpoint, the setup is a bit more complicated than earlier.  Ideally,
we want to mimic a normal implementation.  In a normal implementation, there is a global vector of
objects (memory).  Every object can then be uniquely defined by an address in global memory.  That
is fine without threads.  For threads, we want to have thread local and global memory.  Furthermore,
we don't want threads to stomp on each others memory addresses.  Thus, we need two different address
spaces.  Something like:

vector<Object> global_memory;
vector<Object> local_memory;

As I observe later, we also need a third address space for functions:

vector<Object> function_memory;

Where local_memory is specific to the given thread, and global_memory and function_memory is shared across all threads.
Each object can then be mapped to an address, which is simply the location of that object in memory.
A frame is then marked by simply taking a series of locations from local_memory.  Essentially, local_memory
is the stack for the VM, and global_memory is the (shared) global memory.  That works pretty well.
Persistent variables can be simply be allocated in global_memory, and given an address (depending on if they
are thread local or not).  

The use of addresses eliminates the need for string searches at runtime.  A frame will then consist of
the following operations:

frame::begin()
  local_memory.reserve(variables_used)
  registers.reserve(registers_used)
  name_cache.reserve(variables_used)
end

A LOAD opcode will then do the following.  If the name index referred to by the LOAD opcode has a memory
location, it will simply load the object from local_memory.  A LOAD opcode can also be mapped to global
memory.  Consider, for example, the implicit search for functions.

function b = foo(a)
   b = a + pi
end

Here, "pi" is a symbol defined in global memory (it is a function).  The OP_LOAD for "pi" will search
the symbol table for the frame.  As the symbol is not defined, it will search the global memory space for
the symbol.  If found, the value will be loaded and stored in local_memory in the space reserved for the
"pi" symbol.  This fetch operation is lazy, and triggered by a reference to a variable.  What happens when
we use "eval" to do the same thing?

function b = foo(a)
  eval('b = a + pi')
end

Essentially, the "eval" will be compiled into a series of opcodes that contain a reference to "pi".  That continues
the question to one of open frames.  For open frames, we do not want to reserve memory for the variables.  Those
variables are supposed to exist in the parent scope.  However, that is not guaranteed.  Consider for example

function b = foo(a)
  do_script_makes_x
  b = x + a
end

In this case, the script "do_script_makes_x" creates the variable "x", which is not present in the scope of function
"foo".  So this variable needs to be added to the local_memory allocated in the parent frame, and assigned an
address.  As a result, the OP_LOAD looks something like this:

OP_LOAD:
  Does symbol have a mapping?
    Yes --> load value from designated local memory location
    No  --> Does symbol exist in current frame?
                --> Yes, save mapping and return value
                --> Does symbol exist in function_memory?
                         Yes --> Fetch value from function_memory, and store in local cache & save mapping
                         No  --> throw exception "variable not defined"

OP_SAVE:
  Does symbol have a mapping?
    Yes --> save value to designated location
    No  --> Create symbol in current frame
                --> save mapping
                --> save value to designated location
              

So declared variables (globals, returns, etc.) will always have defined mappings.  Dynamic variables will just be added
to the current symbol table.  

If we don't use the processor stack for the frame.  We have something like

std::vector<Object> stack;

frame::begin(std::vector<Object> &stack)
{
  int sp = stack.size();
  stack.resize(stack.size() + num_registers + num_vars);
  Object *reg = &stack[sp-1];
  Object *var = &stack[sp+num_registers-1];
}

frame::end(std::vector<Object> &stack)
{
  stack.resize(sp);
}

In some cases, a frame will contain variables for which it has no references.  Consider

function foo
   script_that_defines_x
   script_that_uses_x

In this case, no reference to symbol "x" will exist in foo's frame.  Nor will the code segment
contain references to a variable x.  In fact, only the two names of the symbols will be defined
in foo's name list.  This means a frame must have a dynamic map of strings to indexes.  

frame {
  Object *registers;
  Object *variables;
  std::vector<Object> *stack;
  std::map<FMString,int> symbols;
}

Because the symbols map will require heap manipulation, it's not entirely clear what the 
advantage of avoiding it for registers and variables is.  It's certainly simpler to do

frame {
  std::vector<Object> registers;
  std::vector<Object> variables;
  std::map<FMString,int> symbols;
}


The OP_SAVE opcode can then do something like:

OP_SAVE reg,ndx
  - if (address[ndx])
      _closed_frame->variables[address[ndx]


Actually, that's not strictly true.  We can avoid the dynamic allocation of the symbol map
by doing the following.  

frame {
  Object *registers;
  Object *variables;
  std::vector<Object> *stack;
  std::map<FMString,int> dyn_symbols;
}

We can leave dyn_symbols unused unless a script inserts a new symbol into the frame.  The
search and resolve procedure for an OP_SAVE can then add the symbol to the frame.  Something
like:

OP_SAVE reg, ndx
  - if (address[ndx])
      _closed_frame->variables[address[ndx]]
    else
    {
      // Check to see if frame already has a symbol with this name
      if (f->has_symbol_named(names[ndx]))
        address[ndx] = f->get_symbol_address(names[ndx])
      else
      {
        f->add_dynamic_symbol(names[ndx])
        address[ndx] = f->get_symbol_address(names[ndx])
      } 
      f->variables[address[ndx]] = reg
    }


Can the Type class itself be an Object?  Perhaps, but I think it's too
difficult to do now.  

The next problem is to address function calls.  A function call should
be a pointer to a function with the following type signature.

Object func(ThreadContext *ctxt, const Object & argList, int nargout)

A function object can then have the following signature.

Need to build a function pool.  A function pool is a dictionary of
objects (assuming that we have built-in functions as objects as well -
I see no reason not to).

Need classes

Need closures

Need multi-function calls
 -- Change opcode so that passes the function argument count as an
 argument
 --- Something like:  OP_CALL <ret> <func> <arg> <retcount>
 --  Doesn't work, but we can put the number of returns into the
     return register, and then overwrite it.  Although it seems
     cleaner to put it into the argument list.

Need sparse matrices

http://www.ee.columbia.edu/~marios/matlab/Simplify%20your%20code%20with%20comma-separated%20lists.pdf

Interesting.  Here are some relevant snippets.


Comma-separated lists of variables, such as, x,y,z, appear frequently
in MATLAB code; they are most commonly found inside of {}, () and []
. In most cases, specifying the list of variables explicitly is
sufficient, but sometimes you need a more flexible technique. You can
store variable values in a cell array or structure array, and then
expand your data into a comma-separated list via c{:}, if c is a cell,
or via s.field, if s is a structure array. This simplifies certain
problems involving indexing and cell or structure array manipulation
and often allows you to write shorter, more efficient code. The
comma-separated list economizes the syntax for extracting multiple
values from cell and structure arrays. For example, c{:} is equivalent
to c{1},c{2},c{3},...c{end}, a list of values separated by
commas. Similarly for a structure array, s.field is equivalent to
s(1).field,s(2).field,...s(end). field. The four uses of
comma-separated lists are: 2003 Issues May 2003 2002 Issues October
2002 February 2002 Cleve's Corners 1994-2002 Past Issues Spring 2001
Winter 2001 Winter 2000 Summer 1999 Winter 1999 Subscribe Now ￼￼Within
[] to perform horizontal matrix concatenation. For example, if c is a
cell array containing scalars, where c{i} = i, you can create a matrix
consisting of the individual elements of c using [c{:}]. This usage
allows you to convert cell or structure arrays to numeric arrays in an
efficient and convenient manner.  As input or output parameters to
function calls. Functions that take a variable number of input
arguments or return a variable number of outputs can use
comma-separated lists. Use this technique when you need to build
argument lists to functions while your program is executing or when
you need to store the return values from functions in a single
variable, i.e., a cell or structure, for later processing. This usage
is common with functions that use varargin and varargout.  Within ()
to create an indexed expression. This usage is effective when dealing
with n- dimensional arrays (see Pattern 1, below).  Within {} to
create cell arrays. For example, b = {c{:}, magic(3)} creates a cell
array whose elements consists of the elements of cell c and a 3 -by-3
magic square.  Writing code with cell or structure arrays allows you
to take advantage of comma-separated list coding techniques, which are
the foundation for some of the programming patterns in MATLAB.
Pattern 1: Comma-separated lists and indexing Using comma-separated
lists in indexing operations can simplify and speed up your code. For
example, let’s look at the fftshift function.
￼￼￼￼http://www.mathworks.com/company/newsletter/spring01/patterns.shtml
6/8/2003 ￼MATLAB Programming Patterns Page 2 of 4 function y =
fftshift(x) numDims = ndims(x); idx = for k cell(1, numDims); =
1:numDims m = size(x, k); p = ceil(m/2); idx{k} = [p+1:m 1:p]; end y =
x(idx{:}); Given an N-dimensional matrix, fftshift swaps "half-spaces"
along each dimension. This is fundamentally an indexing operation:
given, for example, the vector a = [5 6 7 8 9 0], we can swap the left
and right halves of this vector with the command b = a([4:6 1:3]);
note that since a is one-dimensional, swapping requires only one index
vector. fftshift performs this kind of index-based swapping in N
dimensions and thus must construct N index vectors. The swapping
operation is simply y = x(index1,index2,..., indexN).  if ndims(x) ==
1 y = x(index1); else if ndims(x) == 2 y = x(index1, index2); end If
you are using explicit indexing, you’ll need to write one if statement
for each dimension you want your function to handle. A comma-separated
list makes it very easy to generalize this swapping operation to an
arbitrary number of dimensions.  fftshift stores the index vectors in
a cell array. Building this cell array is relatively simple. For each
of the N dimensions, determine the size of that dimension and find the
integer index nearest the midpoint. Then, construct a vector that
swaps the two halves of that dimension. Once all the vectors have been
collected into this cell array, a single MATLAB command performs the
swap: y = x(idx{:}); This technique produces an algorithm that is
dimension independent and compact.  Pattern 2: Manipulating data in
structure arrays You will often find that using comma-separated lists
to manipulate structure arrays makes it easier to write efficient
code. For example, if you want to search for and replace a certain
value in your structure array, you can easily create a function to do
this.  function index = findinstruct(a, value) % findinstruct takes a
% structure with the field value as its first % argument and a double
search value as its % second argument. This function assumes that the
% structure does not contain NaNs or empties.% Generate the indices of
the desired value index = find([a.value] == value); First, use
findinstruct to get the indices that match the value being
replaced. Note that
http://www.mathworks.com/company/newsletter/spring01/patterns.shtml
6/8/2003 MATLAB Programming Patterns Page 3 of 4 findinstruct converts
its input structure array to a numeric array using [] and a structure
field comma-separated list. Next, replace the existing value with the
new value by issuing this command: [a(index).value] = deal(newval);
You must use the function deal here, rather than a simple assignment
statement, because only functions can assign to multiple left-hand
side values; in this case, deal copies its input into each element of
the output. As a general rule, whenever you need to assign to or from
a comma-separated list, use deal in conjunction with the []
concatenation operator.  Comma-separated lists and objects MATLAB
classes can change the behavior of the cell and structure indexing
operators ({} and .) by overloading the subsref and subsasgn
functions. MATLAB calls subsref when an indexing operation appears on
the right hand side of an assignment statement, and subsasgn when the
indexing appears on the left hand side. For example: subsref: a =
obj{m:n}; subsasgn: obj.distance = value; If obj is an array of
objects, MATLAB applies the same rules it uses for cell and structure
arrays; thus the {} and . operators produce comma-separated
lists. When a comma- separated list appears on either side of an
assignment statement, MATLAB checks that the number of variables on
the left side of the assignment matches the number of values on the
right, and requires that you use deal to perform the assignment (see
Pattern 2). MATLAB performs this test before executing the overloaded
subsref and subsasgn functions by calling the numel function to count
the number of elements in obj{m:n} and obj.distance. The built-in
version of numel returns n—m+1 for the {m:n} case and prod(size(obj))
in the obj.distance case. If there is a mismatch between the number of
values on either side of the assignment as a result of calling numel,
an error occurs and the overloaded subsref and subsasgn functions are
not executed.  Therefore, if you want to modify the behavior of the
comma- separated list operators with respect to object arrays (for
example, your class may use {} to perform string indexing), you need
to indicate to MATLAB that these operators return 1, for the number of
elements. To do this you need to overload the numel function and have
it return 1 for both {} and . cases. With this overloaded numel in
place, the above example assignments do not require the explicit use
of deal, and MATLAB executes the overloaded subsref
andsubsasgnfunctions.  Summary See the help for numel for details on
how to use it.  Using comma-separated lists helps you write compact,
efficient, and extensible code. Because most cell and structure array
operations are built-in functions, the convenience and flexibility
does not come at the cost of performance. When working with
comma-separated lists, you need to remember to use deal
appropriately. And if you’re writing a MATLAB class, you should
consider whether or not to overload numel for that class. With these
points in mind, you will find comma-separated lists a powerful and
effective technique, and a very useful tool to add to your programming
toolkit.


This is also supposed to work...

C = cell(4, 6);
for k = 1:24,   C{k} = k * 2;   end

[c1 c2 c3 c4 c5 c6] = C{1,1:6};

Ultimately, it seems as though I need the concept of a variable
reference - i.e., something that acts as a pointer to an object.  This
allows for two improvements.  One is that the list

[a,b,c,d,e] = foo

can be handled (I think!) by creating a list of LHS references, and
then handling the assignments.  The other advantage is that variables
that are passed by reference work cleaner.  

But it's difficult to get right.  How does it work at the VM level?
Something like:

OP_LOAD_REF:
  // Get address
  REG1 = _ctxt->_objref->makeScalar(address);

// When we do an assignment what happens?  We have somthing like this:

a = 3;
b = &a; // b is now a pointer to a
b = 5;

Then OP_SAVE needs to bo changed so that if varfile[addr] is an
objref, that an additional level of indirection is used in the
assignment.  So that

OP_SAVE:
  if (varfile[addr].isReference())
    // decode address, and write it...

This works for the above example.  But not in the more general case.
How do you use it to pass arguments to functions?  Can't.  Because you
don't know a priori that an argument is passed by reference.  Also,
addresses are local to each frame.  Which means you cannot pass an
address from one frame to another.  

Simpler would be to have

Need slicing to work.

How do we translate A.foo{1:3} into 

A.foo{1},A.foo{2},A.foo{3}

1.  Take the tree of the form:

multi
   []
      variable
         (ident)A
         {}
            :
               (real)1
               (real)3

2.  We then want to select one of the various expressions (we know how
many subexpressions there are from the NUMEL or LENGTH operation
already complete.  How does the selector work?  

If we call A{1:3,2} = b, then setBraces is passed an argument that is a
_list_ of indices

-- so setBraces should be

CellType::setBraces(a, args, b)
{
	if (args is all scalars || b is scalar)
}


a = fixa
a(3,3,3) = 9 --> doesn't work!


(:,:,0) = 
   1.0000   2.0000   3.0000   4.0000
   5.0000   6.0000   7.0000   8.0000
        0        0        0        0

(:,:,1) = 
        0        0        0        0
        0        0        0        0
        0        0        0        0

(:,:,2) = 
        0        0        0        0
        0        0        0        0
        0        0        0   9.0000


(:,:,0) = 
   1.0000   2.0000   1.0000   2.0000   3.0000
   5.0000   6.0000   5.0000   6.0000   7.0000
        0        0        0        0        0

(:,:,1) = 
   4.0000        0        0        0        0
   8.0000        0        0        0        0
        0        0        0        0        0

(:,:,2) = 
        0        0        0        0        0
        0        0        0        0        0
        0        0        0   9.0000   9.0000

a = fixa
a(3,4,3) = 9
a(3,5,2) = 9


********************************************************************************

Structure indexing

Next major hurdle is structure indexing.  Need to spend some time on
this.

- multiple return values with structures

Removal of Null objects

- The main issue with Null objects is the following.  Default creation
  of a NULL object has to lie in a particular thread context.  

Deletion!

Classes


- Null objects removed!  Yaay!  But 

a.foo = 3 

fails now.  Suspect that has more to do with the multiple assignment
fix than the empty array.

********************************************************************************

Deletion...


Review code for opportunities to use

auto
range-for
enum class
std::complex?
use vector instead of void *ptr in Data?
move semantics?

Back to the issue of deletion.  How can deletion be done?  

Review use of makeMatrix for assumption of zeros...


Still bugs with set:

(:,:,0) = 
   1.0000   2.0000   3.0000   4.0000
   5.0000   6.0000   7.0000   8.0000
   8.0000   7.0000   6.0000   4.0000

(:,:,1) = 
   1.0000   2.0000   3.0000   4.0000
   5.0000   6.0000   7.0000   8.0000
   8.0000   7.0000   6.0000   4.0000

(:,:,2) = 
   1.0000   2.0000   3.0000   4.0000
   5.0000   6.0000   7.0000   8.0000
   8.0000   7.0000   6.0000   4.0000

 Execution time 0.000165641
--> a(3,4,:) = 1:3

(:,:,0) = 
   1.0000   2.0000   3.0000   4.0000
   5.0000   6.0000   7.0000   8.0000
   8.0000   7.0000   6.0000   2.0000

(:,:,1) = 
   1.0000   2.0000   3.0000   4.0000
   5.0000   6.0000   7.0000   8.0000
   8.0000   7.0000   6.0000   1.0000

(:,:,2) = 
   1.0000   2.0000   3.0000   4.0000
   5.0000   6.0000   7.0000   8.0000
   8.0000   7.0000   6.0000   3.0000

Deletions still do not work:

a(:,[2,3],:) = []

(:,:,0) = 
   1.0000   4.0000
   5.0000   8.0000
   8.0000   2.0000

(:,:,1) = 
   3.0000   4.0000
   7.0000   8.0000
   6.0000   2.0000

(:,:,2) = 
   1.0000   2.0000
   5.0000   6.0000
   8.0000   7.0000

TODO - 
  Row delete
  

********************************************************************************

Next steps

Calling functions from functions doesn't work? - Done

Review TODOs and FIXMEs

end syntax? - Done

Test cases?

nargin? nargout? varargin? varargout?

Finish NCAT?

Global

Persistent

Switch statement - working - check corner cases

Exceptions - Done!

end syntax is working, but it does not cover the vector case yet.

We have:

a(end) --> end(a,[])

And

a(1,end) --> end(a,[1])

Built in functions...


Exceptions!!!

How are these going to work?

Exceptions have changed.  In FM4, the throw function was just missing!  

We need to sort out objects for exception handling to work properly.
But for now, a throw statement does the following:

1. Stores it's argument in the VM's memory space:
  vm->_exception = REG1
2. Check the handler stack.  If it is empty, exit the VM loop (set
  returnFound).
3. If it is not empty, pop the address, and jump to the address.
4. The OP_CATCH opcode will load the exception if necessary from
  vm->_exception.

This will handle all exception handling within a single function.
What about situations in which one M function is calling another?
One option is to convert the VM exception into a C++ exception.
Then at the end of the VM loop, if the _exception is set, we throw an
Exception.

The flip side is an exception in the C++ code that needs to be
propogated to the VM.  Consider an operation like this:

try
  expression_that_throws_exception
catch
  stuff
end

So in this case, the C++ code with throw an exception.  We have to
catch that exception, which we can do _outside_ the VM execution
loop.  The exception can then trigger the same logic as the throw
Opcode.  Something like this


while (!returnFound)
{
  try {
    VMLoop
  } catch (Exception & e) {
    if vm_has_exception_handler_registered
      vm->_exception = e (somehow)
      vm->_ip = <pop_exception_handler_address>
    else
      throw;
    end
  }
}

Exceptions are done!  They were remarkably easy.  I think there are
still some issues with stack unwinding and functions cleaning up after
themselves.  The executeFunction and executeScript methods of the VM
should use RAII to reserve and unwind the various stacks, variable
allocations, etc.


Handle-type classes are tricky only because of the need to deal with
circular references.  

classdef sads
    % Sensor Array data set class
    properties (Access=private)
        Wavelength   % Wavelength of sources (m)
    end
    properties (Constant)
        c=3e8;       % Speed in medium (m/s)
    end
    properties (Dependent)
        NumSensors   % Number of sensors
        NumSamples   % Number of samples
    end
    properties
        Data         % Sampled sensor data
    end
    properties (Access=private)
        Spacing      % Spacing of array (m)
        SampleRate   % Sample rate (Hz)
        Name         % Sensor array test run name
    end
    methods
        function obj=sads(Data, Wavelength,SampleRate,Spacing,Name)
            % SADS Create sensor array data set
            % Example:
            %  sads(Data, Wavelength,SampleRate,Spacing,Name)

            obj.Data=Data;
            obj.SampleRate=SampleRate;
            obj.Spacing = Spacing;
            obj.Name=Name;
            obj.Wavelength=Wavelength;
        end
        function NumSensors=get.NumSensors(obj)
            % Get NumSensors property
            NumSensors=size(obj.Data,2);
        end
        function NumSamples=get.NumSamples(obj)
            % Get NumSamples property
            NumSamples=size(obj.Data,1);
        end
    end
    methods (Static)
        showarray(Targets,NumSensors,Spacing)
    end
end

So there are two ways to dispatch a method call into an object.
First, you can use the . syntax:

a = a.incr(32)

which should call the "incr" method on object a, with an implicit
first argument of a.  Hence, this is equivalent to:

a = incr(a,32)

From an implementation perspective, they are very different.  In the
case of the first one, the logical option is to bind the method to the
object (logically at construction time).  This won't work for
value-type objects.  As soon as the function is bound, the object
becomes copied.  Instead, a late binding makes more sense (although it
will be more expensive).  In this case, we generate a new function on
the fly that binds the argument to the method function.  I don't know
how quickly that can be done.  Essentially the compiled function looks
like

Name: ''
Names: ''
Parameters: <varargin>
Returns: __obj
Consts: <function def>, <a>

Code:
New List
push <a>
push <varargin{:}>
call function def
return first ret

************************************************************

The other case is more difficult.  

a = incr(a,32)

In this case, the incr function is fetched with a LOAD instruction,
without any reference to a.  It seems as though this is not
stretchable to the standard case.  Instead, we need to replace LOAD
with a new instruction: LOOKUP.  Here, we collect the arguments of
LOOKUP into a list, and then call LOOKUP.  Something like:

new_list r3
push     r3, a
push     r3, 32
lookup   r4, r3, name[1]
subsref 

The lookup OP code can then employ the following logic:

1.  If name[1] is mapped to a local address (i.e., a variable), then
return it's value.
2.  If any user classes, compute the dominant class from r3, and
lookup up name[1] in the methods of that class.  Continue looking
until you find somethin.
3.  Search the global namespace.

The result of LOOKUP cannot be cached unless a local variable has been
assigned.

Consider, for example:

a = {o1,o2,o3,...,oN}

and then

for i=1:N
  foo(a{i})
end

Here, foo may be a different function for each object.

So I will split the opcodes.  OP_LOAD will remain for expressions that
do not get subrefed, like:

A = B + 3

In this case, the lookup for B should be an OP_LOAD.  In the case of

A = B(4) + 3

on the other hand, we need OP_LOOKUP, ans


Compiling function bind
Symbol table is bind
Name: 'bind'
Names: <'add' 't' 'y'>
Parameters: 1
Returns: 2
Consts: 6 
Code: 15 length
000 NEW_LIST       r0                       
001 NEW_LIST       r1                       
002 LOAD_CONST     r2, Const[0]             
003 PUSH           r1, r2                   
004 LOAD           r2, Name[1]              
005 DEREF          r3, r2                   
006 PUSH           r1, r3                   
007 LOOKUP         r2, r1, Name[0]          
008 NEW_LIST       r3                       
009 PUSH_INT       r3, 0                    
010 PUSH           r3, r1                   
011 SUBSREF        r0, r2, r3               
012 FIRST          r1, r0                   
013 SAVE           r1, Name[2]              
014 RETURN                                  


function y = bind(t)
  y = add(6,t);

The code should be something like:

NEW_LIST   r0
PUSH_INT   r0,0
NEW_LIST   r1
LOAD_CONST r2, <add>
PUSH       r1, r2
LOAD       r2, <t>
PUSH       r1, r2
PUSH       r0, r1

Should we use varargin?

new_list r0
push_int r0,0
new_list r1
load_const r2, <6>
push     r1,r2
load     r2, <t>
push     r1,r2
push     r0,r1
load_const r2, <add>
subsref  r3, r2, r0
first    r4, r3
save     r4, 'y'
return

function [z,g,r,a] = multi(x,r,t,c)

      Symbol: a flags:  return dynamic pos=3
      Symbol: c flags:  parameter dynamic pos=3
      Symbol: g flags:  return dynamic pos=1
      Symbol: r flags:  parameter return pos=3
      Symbol: t flags:  parameter dynamic pos=2
      Symbol: x flags:  parameter dynamic pos=0
      Symbol: z flags:  return dynamic pos=0

Names     : <'a' 'c' 'g' 'r' 't' 'x' 'z'>
Parameters: [5 0 4 3 ] - x,a,t,r
Returns   : [6 2 0 3 ] - z,g,a,r

Also need inheritance and synthetic properties...

************************************************************

Handles are still buggy - fixed

Need to add methods

%classdef DocPolynom
   % Documentation example
   % A value class that implements a data type for polynonials
   % See Implementing a Class for Polynomials in the
   % MATLAB documentation for more information.
   
   properties
      coef
   end
   
   % Class methods
   methods
      function obj = DocPolynom(c)
         % Construct a DocPolynom object using the coefficients supplied
         if isa(c,'DocPolynom')
            obj.coef = c.coef;
         else
            obj.coef = c(:).';
         end
      end % DocPolynom
      function obj = set.coef(obj,val)
         if ~isa(val,'double')
            error('Coefficients must be of class double')
         end         
         ind = find(val(:).'~=0);
         if ~isempty(ind);
            obj.coef = val(ind(1):end);
         else
            obj.coef = val;
         end
      end % set.coef
      
      function c = double(obj)
         c = obj.coef;
      end % double
      
      function obj = uminus(obj)
          obj = -1*obj;
      end
      
      function [q,r] = mrdivide(obj1,obj2)
          [q,r] = deconv(obj1.coef,obj2.coef);
          if q ~= 0
            q = DocPolynom(q);
          end
          flag = 0;
          for i=1:length(r)
              if r(i) ~= 0
                  flag = 1;
              end
          end
          if flag == 1
              warning('Polynomial division resulted in a remainder')
              r = DocPolynom(r);
          end
      end
      
      function str = char(obj)
         % Created a formated display of the polynom
         % as powers of x
         if all(obj.coef == 0)
            s = '0';
            str = s;
         else
            d = length(obj.coef)-1;
            s = cell(1,d);
            ind = 1;
            for a = obj.coef;
               if a ~= 0;
                  if ind ~= 1
                     if a > 0
                        s(ind) = {' + '};
                        ind = ind + 1;
                     else
                        s(ind) = {' - '};
                        a = -a; %#ok<FXSET>
                        ind = ind + 1;
                     end
                  end
                  if a ~= 1 || d == 0
                     if a == -1
                        s(ind) = {'-'};
                        ind = ind + 1;
                     else
                        s(ind) = {num2str(a)};
                        ind = ind + 1;
                        if d > 0
                           s(ind) = {'*'};
                           ind = ind + 1;
                        end
                     end
                  end
                  if d >= 2
                     s(ind) = {['x^' int2str(d)]};
                     ind = ind + 1;
                  elseif d == 1
                     s(ind) = {'x'};
                     ind = ind + 1;
                  end
               end
               d = d - 1;
            end
            str = [s{:}];
         end
      end % char
      
      function disp(obj)
         % DISP Display object in MATLAB syntax
         c = char(obj);
         if iscell(c)
            disp(['     ' c{:}])
         else
            disp(c)
         end
      end % disp
      
      function b = subsref(a,s)
         % SUBSREF Implementing the following syntax: 
         % obj([1 ...])
         % obj.coef
         % obj.plot
         % out = obj.method(args)
         % out = obj.method
         switch s(1).type
            case '()'
               ind = s.subs{:};
               b = a.polyval(ind);
            case '.'
               switch s(1).subs
                  case 'coef'
                     b = a.coef;
                  case 'plot'
                     a.plot;
                  otherwise
                     if length(s)>1
                        b = a.(s(1).subs)(s(2).subs{:});
                     else
                        b = a.(s.subs);
                     end
               end
            otherwise
               error('Specify value for x as obj(x)')
         end
      end % subsref
      
      function r = plus(obj1,obj2)
         % PLUS  Implement obj1 + obj2 for DocPolynom
         obj1 = DocPolynom(obj1);
         obj2 = DocPolynom(obj2);
         k = length(obj2.coef) - length(obj1.coef);
         r = DocPolynom([zeros(1,k) obj1.coef] + [zeros(1,-k) obj2.coef]);
      end % plus
      
      function r = mpower(obj1,x)
          obj1 = DocPolynom(obj1);
          if x < 1
              error('DocPolynom can only handle positive, integer powers');
          end
          if (round(x)-x)~= 0
              error('DocPolynom can only handle positive, integer powers');
          end
          r = obj1;
          for i=1:x-1
              r = r*obj1;
          end
      end
      
      function r = minus(obj1,obj2)
         % MINUS Implement obj1 - obj2 for DocPolynoms.
         obj1 = DocPolynom(obj1);
         obj2 = DocPolynom(obj2);
         k = length(obj2.coef) - length(obj1.coef);
         r = DocPolynom([zeros(1,k) obj1.coef] - [zeros(1,-k) obj2.coef]);
      end % minus
      
      function r = mtimes(obj1,obj2)
         % MTIMES   Implement obj1 * obj2 for DocPolynoms.
         obj1 = DocPolynom(obj1);
         obj2 = DocPolynom(obj2);
         r = DocPolynom(conv(obj1.coef,obj2.coef));
      end % mtimes
      
      function r = roots(obj)
         % ROOTS.  ROOTS(obj) is a vector containing the roots of obj.
         r = roots(obj.coef);
      end % roots
      
      function y = polyval(obj,x)
         % POLYVAL  POLYVAL(obj,x) evaluates obj at the points x.
         y = polyval(obj.coef,x);
      end % polyval
      
      function q = diff(obj)
         % DIFF  DIFF(obj) is the derivative of the polynom obj.
         c = obj.coef;
         d = length(c) - 1;  % degree
         q = DocPolynom(obj.coef(1:d).*(d:-1:1));
      end % diff
      
      function plot(obj,varargin)
         % PLOT  PLOT(obj) plots the polynom obj
         if nargin==1
             r = max(abs(roots(obj)));
             x = (-1.1:0.01:1.1)*r;
         else
             x = varargin{1};
         end
         y = polyval(obj,x);
         plot(x,y);
         c = char(obj);
         title(['y = ' c{:}])
         xlabel('X')
         ylabel('Y','Rotation',0)
         grid on
      end % plot
   end % methods 
end % classdef

-- Need to merge the assembler and compiler and clean up the
   compiler.  The module/symbol/stuff is a mess.


To do that, I need to understand the need for the complexity.  This
means local functions and nested functions.

For local functions, the case is relatively easy.  We need to have
constant references to other functions in the same module.  This can
be done by the assembler.

Local functions cannot be stored as constants, because they can be
replaced at run time.  Consider:

function x = foo(y)
  x = square(y);
  square = x*x;
  x = square+2;
end

function y = square(z)
  y = z*z;
end

In this case, the first instance of square is a local function call,
but the second instance is a variable.  If square is compiled with a
LOAD_CONST opcode, then at runtime, the second invocation of square+2
will load from the CONST pool instead of the variable pool.

So this means that local functions are just scoped functions that can
be accessed from within a module.

Why not use the same concept as a class for a module? That means
either a codeblock needs to have a handle class or something.  How
about if we have a module class with the following:

class ModuleMetaData {
public:
  HashMap<Object> m_local_functions;
  Object m_main_function;
  FMString m_name;
};

Modules work great!  Next step is to handle nested functions.  Recall
that a nested function has access to the parent function's variables.
In the case of Python, these are "cell variables".  So consider 

function main1
  x = 5;
  nestfun1

  function nestfun1
    x = x + 1;
  end
end

Idea 1: variables are captured when address of the function is taken.
     - Cons - opcodes required are different.

Idea 2: captured variables are put into a list.  Invokation of nested
functions transfers captured variables to nested function with a
MAKE_CLOSURE type of opcode.
     - Cons - the transferred variables need to be transferred by
     reference, not by value.  Otherwise, modifications in the nested
     function won't be seen at the parent scope.

So essentially a cell has reference semantics.  

>>> def make_counter():
...    i = 0
...    def incr():
...       nonlocal i
...       i += 1
...       return i
...    def decr():
...       nonlocal i
...       i -= 1
...       return i
...    return (incr,decr)
... 
>>> (a,b) = make_counter()
>>> a()
1
>>> a()
2
>>> a()
3
>>> b()
2
>>> b()
1
>>> 


>>> dis.dis(make_counter)
  2           0 LOAD_CONST               1 (0)
              3 STORE_DEREF              0 (i)

  3           6 LOAD_CLOSURE             0 (i)
              9 BUILD_TUPLE              1
             12 LOAD_CONST               2 (<code object incr at 0x1040e7ae0, file "<stdin>", line 3>)
             15 LOAD_CONST               3 ('make_counter.<locals>.incr')
             18 MAKE_CLOSURE             0
             21 STORE_FAST               0 (incr)

  7          24 LOAD_CLOSURE             0 (i)
             27 BUILD_TUPLE              1
             30 LOAD_CONST               4 (<code object decr at 0x1040e7db0, file "<stdin>", line 7>)
             33 LOAD_CONST               5 ('make_counter.<locals>.decr')
             36 MAKE_CLOSURE             0
             39 STORE_FAST               1 (decr)

 11          42 LOAD_FAST                0 (incr)
             45 LOAD_FAST                1 (decr)
             48 BUILD_TUPLE              2
             51 RETURN_VALUE


Essentially, a cell is an unnamed global variable.  To get the same
effect in FreeMat, we need to be able to allocate a global variable
with Handle semantics.  


Need to allocate slots in the consts list for code blocks.

Migrate compiler to smart pointers? Not at the moment...  Some clean
up may be needed - check for leaks.

Write garbage collector? - maybe later

Add LLVM based JIT back in? - maybe later

Next step is to add some more features to the classes

Classes are broken at the moment.

1.  Method invokations don't work.


TODO:

1.  Remove the codeblock stack from the compiler.  Instead, create a
Module and put all code blocks into that module.
2.  Add a typecode to the module to indicate what type of module it is
(i.e., function, script or classdef).

Can we adopt the same methodology as Python for class
creation/definition.  Consider the simplest class

classdef foo
   properties
      prop1
   end
end


This class has just a single property.  The module could be marked as
a classdef module.  The code could be something like:

props = newlist
push props, "prop1"
methods = newlist
name = "foo"
make_class(name,props,methods)

This could create a meta class named "foo" with the given properties
and methods.

Suppose now we have a default value for the property  It seems we
really want more information on the properties:

props = newlist
prop1 = newlist
push prop1, "prop1"
push prop1, FLAG_NORMAL
push prop1, <default_value> or <code_object to compute default value>
push props, prop1
methods = newlist
name = "foo"
make_class(name,props,methods)

The problem is that you need a mechanism to load constants in the
compiler that are later replaced by code blocks by the assembler.  For
now, that means using the "#" notation to create placeholder objects
in the consts list that will then be backpatched by the assembler.

Suppose we now have a constructor

TODO - handle the constructor...

1. Find the metaclass for the class
2. Use the metaclass to construct an instance of the class
3. Call the constructor on the instance.

NO - that's not how it works.  The constructor is automatically
called.  Consider:

      function obj = DocPolynom(c)
         % Construct a DocPolynom object using the coefficients supplied
         if isa(c,'DocPolynom')
            obj.coef = c.coef;
         else
            obj.coef = c(:).';
         end
      end % DocPolynom

In this case, the constructor really has an implicit call of the form

      function obj = DocPolynom(c)
         obj = __construct('DocPolynom')  % <-- Implicit call goes here.
         % Construct a DocPolynom object using the coefficients supplied
         if isa(c,'DocPolynom')
            obj.coef = c.coef;
         else
            obj.coef = c(:).';
         end
      end % DocPolynom

That means we need a special call in the compiler - done - and a new
Opcode has been added to the VM to call the constructor.  

Constructors work.  Next _big_ task is to handle getters and setters
for classes.  These are tricky primarily because of the need to avoid
recursion, and the fact that we cannot a priori identify which element
is the class of which we are a setter/getter.  For example:

      function obj = set.coef(obj,val)
         if ~isa(val,'double')
            error('Coefficients must be of class double')
         end         
         ind = find(val(:).'~=0);
         if ~isempty(ind);
            obj.coef = val(ind(1):end);
         else
            obj.coef = val;
         end
      end % set.coef

Actually, it's not so difficult at all.  When inside a getter or setter
method, access to the class method that is associated with the get/set
operation should bypass setters/getters.  

That means - 

1.  Symbol table needs to be extended to handle get/set operations
2.  Parser needs to accept get/set as part of function name (in this
circumstance only).
3.  



Property attributes to handle:
 - constant
 - dependent

Method attributes to handle:
 - abstract ?
 - access ?
 - hidden ? 
 - sealed ?
 - static



********************************************************************************

Still need to handle a() where a is an array.  Not sure why this
fails, but it does.

Closures do not work from within class methods - why?

Next major event - inheritance

op.(go)

There is a problem with the current implementation of properties as
indexed.  Consider a class 

class foo {
 prop a;
 prop b;
};

If foo maps a->0, b->1.  Then what happens when we subclass from foo?

class bar : foo {
  prop c;
  prop d;
}

Now bar maps c->2, d->3.  This is OK, because bar knows that foo is a
superclass, and therefor allocates slots appropriately.  On the other
hand, if we inherit from two classes,

class bar : foo1, foo2 {
  prop e;
  prop f;
}

We now have an issue, because there is no way to allocate slots so
that both methods of foo1 and foo2 are satisfied.  Multiple
inheritance implies that we must use a map for properties, because
then the name is the key to the map for properties.  How does C++ do
it?  It probably maps out the classes so that

<foo1 properties>
<foo2 properties>
<bar properties>

Then an offset into the class is used to correct the lookup for the
property.  Why can't we just import all of the properties into a
single metaclass?  So that in this case, bar's list of properties is

bar: <foo1_props, foo2_props, bar_props>

We can then import the _methods_ from foo1 and foo2 into the metatype
for bar.  Furthermore, that means that when those functions are called
they are mapped through bar's metatype, which routes them to the
correct slot.  

Inheritance brings the ambiguity in name resolution problem to front.
Consider:

classdef a
      methods
          function foo(x)
	     % Do stuff
          end
      end
end

classdef b < a
      methods
          function foo(x)
	    a@foo(x) % call a's method on x
	    % Do other stuff
	  end
      end
end

In this case, if we have derived b by including the definition of a,
then we must have two methods in class b:

b@foo
a@foo

But we don't want to do a search for b.has('foo'), which is inside the
VM loop.  To that extent, we could duplicate the method which has the
unscoped name.  For example

b@foo
foo

In this case, foo is an alias for a@foo.  But inherited functions will
need to be renamed if/when they clash with existing names.  This
suggests we should add inherited names _after_ local names, with
renaming to avoid collisions.

What remains is calling constructors for inherited classes.  This is a
bit trickier, because the syntax for calling parent class constructors
is a bit wierd.  If class B < class A, then we have an additional
problem in the construction of the class.  Suppose we have that class
A has a constructor which takes arguments:

classdef A
  methods
    function obj = A(c)
      % Stuff goes here
    end
  end
end

Now in this case, you can no longer construct an object of class A
without an argument.  So a derived class now _must_ call A with a
constructor. Consider this case

classdef B < A
  methods
    function obj = B(c)
      % implicit call to construct goes here.
      obj = obj@A(c)
    end
  end
end

This means we must:
1.  In the constructor, scan for invocations of superclasses.
2.  Build a list of constructors that are explicitly called
3.  Identify constructors that still need to be called
4.  emit OP_CONSTRUCT for built-in constructor.

So we need something like this:

class constructor:
1. For each superclass (A) that has no explicit reference, call
meta(A)->deref

A better strategy.

1.  Every class will derive from ValueClass or HandleClass
2.  Compiler tracks the invokation of all constructors done
explicitly.
3.  Constructors not invoked explicitly are implicitly invoked by the
compiler:

function obj = constructorA
  % These are implicit invokations of constructors for base1 and base2
  obj = obj@base1
  obj = obj@base2
  % Explicit invokations of constructors, possibly with arguments
  obj = obj@base3(args)
end

4. Constructors are mapped to functions that take the object to be
constructed as an argument.  This allows constructors from
superclasses and subclasses to be reused.  Hmmm... Consider the case

function obj = base1(c)
  obj.foo = 32
end

In this case, we normally have obj magically assigned by the hidden
OP_CONSTRUCT call inserted at the beginning.  I.e., the code is
compiled as

function obj = base1(c)
  obj = OP_CONSTRUCT
  obj.foo = 32
end

The problem with this is that normally the OP_CONSTRUCT call invokes
the built-in class constructor.  Now, we have a more complicated case
in which base1 is called as the superclass constructor of a derived
class.  For example:

function obj = classA
  obj.goo = 4
end

When this is compiled, it needs to be compiled as

function obj = classA
  obj = OP_CONSTRUCT
  obj = obj@base1 ??
  obj.goo = 4
end

The problem is that we have already constructed obj.  So we cannot
call OP_CONSTRUCT again.  Instead, we need to pass a partially
constructed object to the constructor.  One option would be to have
OP_CONSTRUCT take an argument object.  I.e., what if we have
OP_CONSTRUCT have the following behavior:

1. OP_CONSTRUCT - if called the first time, allocates and constructs
the object with baseline values for all properties.
2. OP_CONSTRUCT - if called subsequent times, returns the already
constructed object.

Examining the OP_CONSTRUCT opcode implementation:
 REG1 = _ctxt->_meta->construct(REG2);

Here REG2 is the metaclass, and REG1 is the returned object of a given
class.  The problem is that there is nowhere to "stash" the partially
constructed object.  Only the return value of construct is saved.  It
would have to live in the current frame or worse, the current VM.
Storing in the current VM or frame won't really work, as the frame
will be pushed when subclass or superclass constructors are called,
and the VM can't keep track of what class is being constructed.

What we need is to make _explicit_ the need to call the original
constructor.  That won't work if we have multiple class inheritance -
e.g., if:

a < b & c

then the base constructor gets called twice.  Once for b and once for
c.

Another option is to add a hidden extra argument to the object
constructor.  So for example,

function obj = classA(n,m)
end

compiles as

function obj = classA(obj,n,m)
end

where obj is the partially constructed object.  We must then in the
setup for the function, handle the fact that obj and n and m are not
equivalent to standard arguments.  Let's ignore this for a moment.
Then when we call base constructors, we have something like this:

function obj = classA(obj,n,m)
  obj = obj@base1(m) --> base1(obj,m)
end

I.e., we add an implicit first argument to the class constructor that
is the partial object.  We need to ensure that this implicit argument
is removed and not counted by nargin.  The remaining problem is that
when the class is constructed, we need to provide a base object.  This
could be done by intercepting the constructor call at the meta object
level.  So something like this:

a = classA(3,4)

--> REG1 = meta.classA.construct()
--> REG1 = meta.classA.call(REG1,3,4)

Here, we external to the constructor (at the VM level) construct the
object A, and then use the constructor to fill in the details.  This
notion of a "hidden" parameter to the function is the same as the
binding, so it's a bit strange that we can't use the same mechanism as
function binding.  This solves the issue for objects without
constructors (REG1 is already the constructed object), and also for
reusing constructors.  Consider if A < base1 & base2.  Then

a = classA(3,4)

REG1 = meta.classA.construct()
REG1 = meta.classA.call(REG1,3,4)
  REG1 = base1(REG1,3)
  REG1 = base2(REG1,4)
The calls to base1 and base2 do not include calls to the construct()
method, so there is no conflict.  This also cleans up the need to
insert OP_CONSTRUCT into the OpCode stream.  In fact, we can eliminate
VM support for it completely.  


********************************************************************************

OK - so the problem was:

1.  Constructors need to be passed an extra argument.
2.  The argument is hidden.
3.  The argument is the same as the return of the function.
4.  Constructors are static functions.
5.  Calling a constructor is a special invocation.

Update.  Some validation is now done on constructors.  For example,

function A = classname(A)
end

or 

function [A,B] = classname()

should both cause errors (reuse of return name in constructor, and too
many return values in a constructor respectively).  What is needed
next is the ability to pass A into constructor without an object.  

How to hide the argument?  Consider the seuqence for calling a
constructor function:

A bound function is different.  In the case of a bound function, the
argument is _added_ to the list of arguments.  So that

y = a.foo(c,d)

becomes 

y = foo(a,c,d)

In this case, we want

y = foo(c,d)

to be converted into:

a = meta(foo).construct(a,b)

So far, this is fine.  

y = foo(c,d)

Then,

1.  The meta class calls "construct" on the class.
2.  The meta class passes control to the class constructor, using a
hidden object parameter.
3.  Calls to superclasses route through the same hidden object
parameter

The first two work - the third one works too.

********************************************************************************

Still needed:

1.  Notification.
2.  Handle classes. - done
3.  Dependency trees. - done
4.  Priorities?
5.  Implicit constructor calls.  FreeMat must call the no-arg
constructors for all super classes that are not explicitly called. :(

Handle classes work, but do not have garbage collection.  So there is
still an issue with cycle detection.

Next - notifications.

Need to add two new types of function pointers:

@obj.Method

and

@class.Method

Also, we need to add sparse matrix support!

Need to add destructor support for handle classes

Operator overloading?

There is a problem with the reference count.  It is too high - that
was fixed.

Need to add method and class function pointers.



The current approach of putting '@' into alphanumerics for the scanner
is wrong.  Need to take it out and treat it like an operator again.

Function pointers also don't seem to work...  Ugh.


The expression a = @add should create an object of class function
pointer

Pointers to anonymous functions is equivalent to closures.  So we
should be able to piggy back on the closure mechanism for anonymous
functions - not sure how just yet.

Anonymous functions inside closed scopes work fine, I think.

Yes - with some (significant!) tweaking, you can now return anonymous
functions from inside closed scopes.  Something like:

function y = foo(a,b)
  y = @(n) a+b+n

This works correctly.  However, what doesn't work is anonymous
functions generated in scripts.  What happens in the case of something
like

function y = foo(a,b)
  y = @(n) fft(a,b,n)

In this case, we have a function fft, which isn't defined in the
parent scope.  In this case, the add function is left as dynamic in
the captured/nested function.  This means a definition of "add" must
exist when the function is _called_.  But this is problematic.

How to resolve?

Ick.  Consider the case where we have:

function y = foo(a,b)
  y = @(n) foo(n,a,b)

In the most general case, the function foo can depend on the types of
the arguments.  That means it cannot be captured as a function when
the closure is created.

I have few alternatives.  One is to look for instances of variable
references without arguments. 

--- Need to think about this some more.

What about function handles for class methods?

y = class@method

This should _always_ return a function handle.  

How do function handles differ from function types?  At the moment,
function types respond to "deref".  So consider the following

y = pi;

if pi is a function, then when we fetch it, we want a function object,
not a handle.  On the other hand

y = @pi

is supposed to return a handle, not a function.  So I think that
closures should be handles, not functions.

For anonymous functions, we have a bit of a problem.  Consider

y = @(x) foo(x)

There are two possibilities.  One is that foo is defined and is a
variable.  If that is the case, then all should be fine, and y should
capture a copy of variable foo.

The second case is that foo is a function and what function gets
executed depends on the type of the argument x.

In the first case, we capture foo as a variable in the caller's space,
and in the second we don't.  This decision has to be made at runtime
by the VM.  But it cannot be made until the function is invoked
(unless it is a variable).  In that case, the instruction has to be
rewritten (it is not an OP_LOAD_CELL), it is an OP_LOOKUP.

It seems that the alternative for anonymous functions is to use a
completely different mechanism.

We want something like

OP_LOOKUP foo, args

How about the following.  First, we convert the expression into a code
object.

So

y = @(x) x + n

We assume all unknown variables are dynamic (i.e., as if it weren't
nested)

Then we have x as a parameter, and n as dynamic.

We then have an opcode OP_MAKE_ANONYMOUS

which takes a code object (constant), and creates an anonymous
function object at run time.


With much effort(!) anonymous functions work again.  So do scoped
pointers.  Need to fix up calls to superclass constructors.

And also handle non-static methods for superclasses.  E.g.,

classdef foo < bar
  methods
    function x = baz(obj)
      x = bar@junk(obj)  % Non-static method from super-class
    end
  end
end

************************************************************

The solution for constructors is still ugly.  Instead, I need to use a
more straightforward approach. For a constructor of the type:

function obj = foo(n)
end

I will synthesize an argument in the list, so that it looks like this:

function obj = foo(obj,n)
end

The constructor then becomes a static method on the meta class.
However, it is not called directly - rather, the meta class calls
"construct" to build the data structure in memory, and then invokes
the constructor with the initial argument set to obj. 


Things to check for objects:

Base constructor - works
Superclass constructor - works
Object method - works
Superclass method - works

At this point, there are no guards for the objects.  For example, if
we have:

class bar
  method
     foo

Then we can call foo on an object that is _not_ derived from bar.

x = junk
bar@foo(x)

This violates the contract.  We need to have some validation that
non-static class methods are invoked on objects?  But there is no
guarantee which argument of the method is supposed to be the object.
So I don't think that will work.

// todo - handle nargin for constructors
// todo - base constructors for superclasses that are not explicitly
called

Base constructors -- we need to call the base constructors for each
class that we derive from.  For example:

classdef bar < foo & baz

Then in the constructor for bar, we have to call the constructors for
foo and baz.  Furthermore, we need to call any constructors for which
the base constructor is not explicitly called.  

Symbol pass now identifies them.. Need to add code to constructor to
call implicit constructors!

Notifications...

Naming events

Event parsing is completed -- but does handle inheritance work
correctly?


Handle inheritance doesn't work correctly.


Solution!  Define the handle class as having a property is_handle = 1,
or something.  Then every class can simply inherit from the handle
class and it will automatically get a member indicating it is a handle
class!
